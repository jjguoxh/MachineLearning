# æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿæ”¹è¿›å»ºè®®

## ğŸ¯ å½“å‰é—®é¢˜è¯Šæ–­

### 1. å¯èƒ½çš„é—®é¢˜åŸå› 
- **æ ‡ç­¾è´¨é‡å·®**: æ ‡ç­¾ç”Ÿæˆé€»è¾‘å¯èƒ½ä¸åˆç†ï¼Œå¯¼è‡´å™ªå£°æ ‡ç­¾
- **ç‰¹å¾ä¸è¶³**: ç‰¹å¾å·¥ç¨‹ä¸å¤Ÿå……åˆ†ï¼Œç¼ºå°‘å…³é”®çš„æŠ€æœ¯æŒ‡æ ‡
- **æ¨¡å‹è¿‡æ‹Ÿåˆ**: æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°å¥½ï¼Œä½†æ³›åŒ–èƒ½åŠ›å·®
- **æ•°æ®ä¸å¹³è¡¡**: å„ç±»åˆ«æ ·æœ¬æ•°é‡ä¸å‡è¡¡
- **è¶…å‚æ•°ä¸å½“**: å­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ç­‰å‚æ•°è®¾ç½®ä¸åˆç†

## ğŸš€ å…·ä½“æ”¹è¿›æ–¹æ¡ˆ

### 1. æ•°æ®è´¨é‡æ”¹è¿›

#### 1.1 æ”¹è¿›æ ‡ç­¾ç”Ÿæˆç­–ç•¥
```python
# ä½¿ç”¨æ›´ç¨³å¥çš„æ ‡ç­¾ç”Ÿæˆæ–¹æ³•
def improved_label_generation(df, window_size=60, profit_threshold=0.02):
    """
    æ”¹è¿›çš„æ ‡ç­¾ç”Ÿæˆï¼š
    1. ä½¿ç”¨æœªæ¥æ”¶ç›Šç‡ä½œä¸ºæ ‡ç­¾
    2. åŠ å…¥é£é™©è°ƒæ•´
    3. è€ƒè™‘äº¤æ˜“æˆæœ¬
    """
    labels = []
    for i in range(len(df) - window_size):
        current_price = df['index_value'].iloc[i]
        future_prices = df['index_value'].iloc[i+1:i+window_size+1]
        
        # è®¡ç®—æœªæ¥æœ€å¤§æ”¶ç›Šå’Œæœ€å¤§æŸå¤±
        max_gain = (future_prices.max() - current_price) / current_price
        max_loss = (current_price - future_prices.min()) / current_price
        
        # é£é™©è°ƒæ•´çš„æ ‡ç­¾ç”Ÿæˆ
        if max_gain > profit_threshold and max_gain > max_loss * 1.5:
            labels.append(1)  # åšå¤š
        elif max_loss > profit_threshold and max_loss > max_gain * 1.5:
            labels.append(-1)  # åšç©º
        else:
            labels.append(0)  # æ— æ“ä½œ
    
    return labels
```

#### 1.2 æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
```python
def advanced_data_cleaning(df):
    """
    é«˜çº§æ•°æ®æ¸…æ´—
    """
    # 1. å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
    for col in ['a', 'b', 'c', 'd', 'index_value']:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower_bound, upper_bound)
    
    # 2. ç¼ºå¤±å€¼æ™ºèƒ½å¡«å……
    df = df.interpolate(method='linear')
    
    # 3. æ•°æ®å¹³æ»‘ï¼ˆå»é™¤é«˜é¢‘å™ªå£°ï¼‰
    for col in ['a', 'b', 'c', 'd', 'index_value']:
        df[f'{col}_smooth'] = df[col].rolling(window=3, center=True).mean()
    
    return df
```

### 2. ç‰¹å¾å·¥ç¨‹æ”¹è¿›

#### 2.1 å¢åŠ æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
```python
def add_technical_indicators(df):
    """
    æ·»åŠ é‡è¦çš„æŠ€æœ¯æŒ‡æ ‡
    """
    # RSI
    delta = df['index_value'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    # MACD
    ema_12 = df['index_value'].ewm(span=12).mean()
    ema_26 = df['index_value'].ewm(span=26).mean()
    df['macd'] = ema_12 - ema_26
    df['macd_signal'] = df['macd'].ewm(span=9).mean()
    
    # å¸ƒæ—å¸¦
    sma_20 = df['index_value'].rolling(window=20).mean()
    std_20 = df['index_value'].rolling(window=20).std()
    df['bb_upper'] = sma_20 + (std_20 * 2)
    df['bb_lower'] = sma_20 - (std_20 * 2)
    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / sma_20
    
    # ATR (å¹³å‡çœŸå®æ³¢å¹…)
    high_low = df['index_value'].rolling(window=2).max() - df['index_value'].rolling(window=2).min()
    df['atr'] = high_low.rolling(window=14).mean()
    
    return df
```

#### 2.2 å¤šæ—¶é—´æ¡†æ¶ç‰¹å¾
```python
def add_multi_timeframe_features(df):
    """
    æ·»åŠ å¤šæ—¶é—´æ¡†æ¶ç‰¹å¾
    """
    for window in [5, 10, 20, 50]:
        # ç§»åŠ¨å¹³å‡
        df[f'ma_{window}'] = df['index_value'].rolling(window=window).mean()
        
        # ç›¸å¯¹ä½ç½®
        df[f'position_{window}'] = (df['index_value'] - df[f'ma_{window}']) / df[f'ma_{window}']
        
        # åŠ¨é‡
        df[f'momentum_{window}'] = df['index_value'].pct_change(window)
        
        # æ³¢åŠ¨ç‡
        df[f'volatility_{window}'] = df['index_value'].pct_change().rolling(window=window).std()
    
    return df
```

### 3. æ¨¡å‹æ¶æ„æ”¹è¿›

#### 3.1 æ³¨æ„åŠ›æœºåˆ¶æ”¹è¿›
```python
class ImprovedTransformerClassifier(nn.Module):
    def __init__(self, input_dim, model_dim, num_heads, num_layers, num_classes, dropout=0.1):
        super().__init__()
        self.model_dim = model_dim
        
        # è¾“å…¥å±‚
        self.input_fc = nn.Linear(input_dim, model_dim)
        self.layer_norm1 = nn.LayerNorm(model_dim)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoder = PositionalEncoding(model_dim)
        
        # Transformerç¼–ç å™¨ï¼ˆå¸¦æ®‹å·®è¿æ¥ï¼‰
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=model_dim,
            nhead=num_heads,
            dim_feedforward=model_dim * 4,
            dropout=dropout,
            activation='gelu',  # ä½¿ç”¨GELUæ¿€æ´»å‡½æ•°
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # è‡ªé€‚åº”æ± åŒ–
        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)
        
        # åˆ†ç±»å¤´
        self.classifier = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(model_dim, model_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(model_dim // 2, num_classes)
        )
    
    def forward(self, x):
        # è¾“å…¥æŠ•å½±å’Œå½’ä¸€åŒ–
        x = self.layer_norm1(self.input_fc(x))
        
        # ä½ç½®ç¼–ç 
        x = self.pos_encoder(x)
        
        # Transformerç¼–ç 
        x = self.transformer_encoder(x)
        
        # è‡ªé€‚åº”æ± åŒ–
        x = x.transpose(1, 2)  # (batch, seq, features) -> (batch, features, seq)
        x = self.adaptive_pool(x).squeeze(-1)  # (batch, features)
        
        # åˆ†ç±»
        return self.classifier(x)
```

#### 3.2 é›†æˆå­¦ä¹ 
```python
class EnsembleModel(nn.Module):
    def __init__(self, models):
        super().__init__()
        self.models = nn.ModuleList(models)
        self.weights = nn.Parameter(torch.ones(len(models)) / len(models))
    
    def forward(self, x):
        outputs = []
        for model in self.models:
            outputs.append(model(x))
        
        # åŠ æƒå¹³å‡
        weighted_output = sum(w * out for w, out in zip(self.weights, outputs))
        return weighted_output
```

### 4. è®­ç»ƒç­–ç•¥æ”¹è¿›

#### 4.1 é«˜çº§æŸå¤±å‡½æ•°
```python
class FocalLoss(nn.Module):
    """
    Focal Loss - å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
    """
    def __init__(self, alpha=1, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()

class WeightedFocalLoss(nn.Module):
    """
    ç»“åˆç±»åˆ«æƒé‡å’ŒFocal Loss
    """
    def __init__(self, class_weights, alpha=1, gamma=2):
        super().__init__()
        self.class_weights = class_weights
        self.alpha = alpha
        self.gamma = gamma
        
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, weight=self.class_weights, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()
```

#### 4.2 å­¦ä¹ ç‡è°ƒåº¦
```python
def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):
    """
    ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦ï¼Œå¸¦é¢„çƒ­
    """
    def lr_lambda(current_step):
        if current_step < num_warmup_steps:
            return float(current_step) / float(max(1, num_warmup_steps))
        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))
    
    return LambdaLR(optimizer, lr_lambda)
```

#### 4.3 æ•°æ®å¢å¼º
```python
def data_augmentation(X, y, noise_factor=0.01):
    """
    æ—¶é—´åºåˆ—æ•°æ®å¢å¼º
    """
    augmented_X = []
    augmented_y = []
    
    for i in range(len(X)):
        # åŸå§‹æ•°æ®
        augmented_X.append(X[i])
        augmented_y.append(y[i])
        
        # æ·»åŠ å™ªå£°
        noise = np.random.normal(0, noise_factor, X[i].shape)
        augmented_X.append(X[i] + noise)
        augmented_y.append(y[i])
        
        # æ—¶é—´æ‰°åŠ¨ï¼ˆè½»å¾®çš„æ—¶é—´åç§»ï¼‰
        if len(X[i]) > 2:
            shifted = np.roll(X[i], 1, axis=0)
            augmented_X.append(shifted)
            augmented_y.append(y[i])
    
    return np.array(augmented_X), np.array(augmented_y)
```

### 5. è¯„ä¼°å’ŒéªŒè¯æ”¹è¿›

#### 5.1 æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
```python
def time_series_cv(X, y, n_splits=5):
    """
    æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
    """
    splits = []
    total_len = len(X)
    
    for i in range(n_splits):
        train_end = int(total_len * (i + 1) / (n_splits + 1))
        val_start = train_end
        val_end = int(total_len * (i + 2) / (n_splits + 1))
        
        train_idx = list(range(train_end))
        val_idx = list(range(val_start, val_end))
        
        splits.append((train_idx, val_idx))
    
    return splits
```

#### 5.2 é‡‘èæŒ‡æ ‡è¯„ä¼°
```python
def evaluate_trading_performance(predictions, prices):
    """
    è¯„ä¼°äº¤æ˜“æ€§èƒ½
    """
    returns = []
    positions = []
    
    for i, pred in enumerate(predictions):
        if pred == 1:  # ä¹°å…¥ä¿¡å·
            positions.append(1)
        elif pred == -1:  # å–å‡ºä¿¡å·
            positions.append(-1)
        else:
            positions.append(0)
    
    # è®¡ç®—æ”¶ç›Š
    for i in range(1, len(positions)):
        if positions[i-1] != 0:
            ret = (prices[i] - prices[i-1]) / prices[i-1] * positions[i-1]
            returns.append(ret)
    
    if returns:
        total_return = np.sum(returns)
        sharpe_ratio = np.mean(returns) / np.std(returns) if np.std(returns) > 0 else 0
        win_rate = len([r for r in returns if r > 0]) / len(returns)
        
        return {
            'total_return': total_return,
            'sharpe_ratio': sharpe_ratio,
            'win_rate': win_rate,
            'num_trades': len(returns)
        }
    
    return None
```

## ğŸ“Š å®æ–½å»ºè®®

### ä¼˜å…ˆçº§é¡ºåº
1. **é«˜ä¼˜å…ˆçº§**: æ”¹è¿›æ ‡ç­¾ç”Ÿæˆå’Œç‰¹å¾å·¥ç¨‹
2. **ä¸­ä¼˜å…ˆçº§**: ä¼˜åŒ–æ¨¡å‹æ¶æ„å’ŒæŸå¤±å‡½æ•°
3. **ä½ä¼˜å…ˆçº§**: å®æ–½é›†æˆå­¦ä¹ å’Œé«˜çº§éªŒè¯

### å…·ä½“å®æ–½æ­¥éª¤
1. é¦–å…ˆè¿è¡Œæ”¹è¿›ç‰ˆé¢„æµ‹è„šæœ¬ `predict_improved.py` æŸ¥çœ‹å½“å‰æ•ˆæœ
2. æ ¹æ®åˆ†æç»“æœé‡æ–°ç”Ÿæˆæ›´å¥½çš„æ ‡ç­¾
3. å¢åŠ æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
4. è°ƒæ•´æ¨¡å‹è¶…å‚æ•°
5. ä½¿ç”¨æ›´å¥½çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
6. å®æ–½äº¤å‰éªŒè¯è¯„ä¼°

### ç›‘æ§æŒ‡æ ‡
- **æ¨¡å‹æŒ‡æ ‡**: å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
- **äº¤æ˜“æŒ‡æ ‡**: æ€»æ”¶ç›Šç‡ã€å¤æ™®æ¯”ç‡ã€èƒœç‡ã€æœ€å¤§å›æ’¤
- **ç¨³å®šæ€§æŒ‡æ ‡**: é¢„æµ‹ä¸€è‡´æ€§ã€ç½®ä¿¡åº¦åˆ†å¸ƒ

é€šè¿‡è¿™äº›æ”¹è¿›ï¼Œé¢„æµ‹æ•ˆæœåº”è¯¥ä¼šæœ‰æ˜¾è‘—æå‡ï¼