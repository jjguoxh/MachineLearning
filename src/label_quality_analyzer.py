"""
æ ‡ç­¾è´¨é‡åˆ†æå·¥å…·
ç”¨äºè¯Šæ–­å½“å‰æ ‡ç­¾ç”Ÿæˆç­–ç•¥çš„é—®é¢˜ï¼Œå¹¶æä¾›æ”¹è¿›å»ºè®®
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
from collections import Counter

def analyze_label_quality(csv_file):
    """
    åˆ†æå•ä¸ªæ–‡ä»¶çš„æ ‡ç­¾è´¨é‡
    """
    print(f"\nåˆ†ææ–‡ä»¶: {csv_file}")
    df = pd.read_csv(csv_file)
    
    if 'label' not in df.columns:
        print("âŒ æ–‡ä»¶ä¸­æ²¡æœ‰labelåˆ—")
        return None
    
    labels = df['label'].values
    index_values = df['index_value'].values
    
    # 1. æ ‡ç­¾åˆ†å¸ƒåˆ†æ
    label_counts = Counter(labels)
    total_labels = len(labels)
    
    print("ğŸ“Š æ ‡ç­¾åˆ†å¸ƒ:")
    label_names = {0: 'æ— æ“ä½œ', 1: 'åšå¤šå¼€ä»“', 2: 'åšå¤šå¹³ä»“', 3: 'åšç©ºå¼€ä»“', 4: 'åšç©ºå¹³ä»“'}
    for label, count in sorted(label_counts.items()):
        percentage = count / total_labels * 100
        label_name = label_names.get(label, f'æœªçŸ¥æ ‡ç­¾{label}')
        print(f"   {label_name}: {count} ({percentage:.1f}%)")
    
    # 2. æ ‡ç­¾è¿ç»­æ€§åˆ†æ
    label_changes = np.diff(labels != 0).sum()
    signal_density = np.sum(labels != 0) / total_labels
    print(f"\nğŸ”„ æ ‡ç­¾è¿ç»­æ€§:")
    print(f"   ä¿¡å·å˜åŒ–æ¬¡æ•°: {label_changes}")
    print(f"   ä¿¡å·å¯†åº¦: {signal_density:.3f}")
    
    # 3. æ ‡ç­¾æœ‰æ•ˆæ€§åˆ†æï¼ˆæ£€æŸ¥æ ‡ç­¾æ˜¯å¦ä¸ä»·æ ¼å˜åŒ–ä¸€è‡´ï¼‰
    analyze_label_effectiveness(labels, index_values)
    
    # 4. æ ‡ç­¾æ—¶é—´åˆ†å¸ƒ
    analyze_label_timing(labels)
    
    return {
        'file': csv_file,
        'label_distribution': label_counts,
        'signal_density': signal_density,
        'label_changes': label_changes
    }

def analyze_label_effectiveness(labels, prices):
    """
    åˆ†ææ ‡ç­¾çš„æœ‰æ•ˆæ€§ - æ£€æŸ¥æ ‡ç­¾æ˜¯å¦ä¸å®é™…ä»·æ ¼å˜åŒ–ä¸€è‡´
    """
    print(f"\nâœ… æ ‡ç­¾æœ‰æ•ˆæ€§åˆ†æ:")
    
    # æ‰¾åˆ°æ‰€æœ‰äº¤æ˜“ä¿¡å·
    long_entries = np.where(labels == 1)[0]
    long_exits = np.where(labels == 2)[0]
    short_entries = np.where(labels == 3)[0]
    short_exits = np.where(labels == 4)[0]
    
    def analyze_signal_effectiveness(entry_points, exit_points, signal_type):
        if len(entry_points) == 0:
            print(f"   {signal_type}: æ— ä¿¡å·")
            return
        
        profits = []
        for entry_idx in entry_points:
            # æ‰¾åˆ°æœ€è¿‘çš„å¹³ä»“ç‚¹
            future_exits = exit_points[exit_points > entry_idx]
            if len(future_exits) > 0:
                exit_idx = future_exits[0]
                if signal_type == "åšå¤š":
                    profit = (prices[exit_idx] - prices[entry_idx]) / prices[entry_idx]
                else:  # åšç©º
                    profit = (prices[entry_idx] - prices[exit_idx]) / prices[entry_idx]
                profits.append(profit)
        
        if profits:
            win_rate = np.sum(np.array(profits) > 0) / len(profits)
            avg_profit = np.mean(profits)
            print(f"   {signal_type}: {len(profits)}ä¸ªäº¤æ˜“, èƒœç‡: {win_rate:.2%}, å¹³å‡æ”¶ç›Š: {avg_profit:.4f}")
        else:
            print(f"   {signal_type}: æ— å®Œæ•´äº¤æ˜“")
    
    analyze_signal_effectiveness(long_entries, long_exits, "åšå¤š")
    analyze_signal_effectiveness(short_entries, short_exits, "åšç©º")

def analyze_label_timing(labels):
    """
    åˆ†ææ ‡ç­¾çš„æ—¶é—´åˆ†å¸ƒ
    """
    print(f"\nâ° æ ‡ç­¾æ—¶é—´åˆ†å¸ƒ:")
    
    # è®¡ç®—ä¿¡å·é—´éš”
    signal_indices = np.where(labels != 0)[0]
    if len(signal_indices) > 1:
        intervals = np.diff(signal_indices)
        print(f"   å¹³å‡ä¿¡å·é—´éš”: {np.mean(intervals):.1f} ä¸ªæ—¶é—´ç‚¹")
        print(f"   æœ€å°ä¿¡å·é—´éš”: {np.min(intervals)} ä¸ªæ—¶é—´ç‚¹")
        print(f"   æœ€å¤§ä¿¡å·é—´éš”: {np.max(intervals)} ä¸ªæ—¶é—´ç‚¹")
    
    # æ£€æŸ¥ä¿¡å·èšé›†æƒ…å†µ
    consecutive_signals = 0
    for i in range(1, len(labels)):
        if labels[i] != 0 and labels[i-1] != 0:
            consecutive_signals += 1
    
    print(f"   è¿ç»­ä¿¡å·æ•°: {consecutive_signals}")

def plot_label_analysis(csv_file, output_dir="../analysis/"):
    """
    ç»˜åˆ¶æ ‡ç­¾åˆ†æå›¾è¡¨
    """
    df = pd.read_csv(csv_file)
    if 'label' not in df.columns:
        return
    
    os.makedirs(output_dir, exist_ok=True)
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # å­å›¾1: ä»·æ ¼å’Œæ ‡ç­¾
    ax1.plot(df['index_value'], label='Price', alpha=0.7)
    
    # æ ‡è®°ä¸åŒçš„æ ‡ç­¾ç‚¹
    colors = {1: 'red', 2: 'red', 3: 'green', 4: 'green'}
    markers = {1: '^', 2: 'v', 3: '^', 4: 'v'}
    labels_map = {1: 'Long Entry', 2: 'Long Exit', 3: 'Short Entry', 4: 'Short Exit'}
    
    for label_type in [1, 2, 3, 4]:
        indices = np.where(df['label'] == label_type)[0]
        if len(indices) > 0:
            ax1.scatter(indices, df['index_value'].iloc[indices], 
                       color=colors[label_type], marker=markers[label_type], 
                       s=50, label=labels_map[label_type], alpha=0.8)
    
    ax1.set_title('ä»·æ ¼å›¾è¡¨ä¸æ ‡ç­¾åˆ†å¸ƒ')
    ax1.set_ylabel('ä»·æ ¼')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # å­å›¾2: æ ‡ç­¾åˆ†å¸ƒé¥¼å›¾
    label_counts = df['label'].value_counts()
    label_names = {0: 'æ— æ“ä½œ', 1: 'åšå¤šå¼€ä»“', 2: 'åšå¤šå¹³ä»“', 3: 'åšç©ºå¼€ä»“', 4: 'åšç©ºå¹³ä»“'}
    labels_for_pie = [label_names.get(i, f'æ ‡ç­¾{i}') for i in label_counts.index]
    
    ax2.pie(label_counts.values, labels=labels_for_pie, autopct='%1.1f%%', startangle=90)
    ax2.set_title('æ ‡ç­¾åˆ†å¸ƒ')
    
    # å­å›¾3: ä¿¡å·æ—¶é—´åˆ†å¸ƒ
    signal_mask = df['label'] != 0
    signal_positions = np.where(signal_mask)[0]
    if len(signal_positions) > 0:
        ax3.hist(signal_positions, bins=50, alpha=0.7, edgecolor='black')
        ax3.set_title('ä¿¡å·æ—¶é—´åˆ†å¸ƒ')
        ax3.set_xlabel('æ—¶é—´ç‚¹')
        ax3.set_ylabel('ä¿¡å·æ•°é‡')
        ax3.grid(True, alpha=0.3)
    
    # å­å›¾4: ä»·æ ¼å˜åŒ–vsæ ‡ç­¾
    price_changes = df['index_value'].pct_change().fillna(0)
    for label_type in [1, 2, 3, 4]:
        label_indices = df['label'] == label_type
        if label_indices.sum() > 0:
            ax4.scatter(np.where(label_indices)[0], price_changes[label_indices], 
                       color=colors[label_type], label=labels_map[label_type], alpha=0.6)
    
    ax4.set_title('æ ‡ç­¾ç‚¹çš„ä»·æ ¼å˜åŒ–')
    ax4.set_xlabel('æ—¶é—´ç‚¹')
    ax4.set_ylabel('ä»·æ ¼å˜åŒ–ç‡')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    base_name = os.path.splitext(os.path.basename(csv_file))[0]
    output_file = os.path.join(output_dir, f"{base_name}_label_analysis.png")
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"ğŸ“ˆ åˆ†æå›¾è¡¨å·²ä¿å­˜: {output_file}")
    plt.close()

def comprehensive_label_analysis(data_dir="../data_with_complete_labels/"):
    """
    å¯¹æ‰€æœ‰æ•°æ®æ–‡ä»¶è¿›è¡Œç»¼åˆæ ‡ç­¾åˆ†æ
    """
    print("ğŸ” å¼€å§‹ç»¼åˆæ ‡ç­¾è´¨é‡åˆ†æ...")
    
    # æŸ¥æ‰¾æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = glob.glob(os.path.join(data_dir, "*.csv"))
    
    if not csv_files:
        print(f"âŒ åœ¨ç›®å½• {data_dir} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    all_results = []
    
    for csv_file in csv_files:
        try:
            result = analyze_label_quality(csv_file)
            if result:
                all_results.append(result)
                # ç”Ÿæˆå¯è§†åŒ–åˆ†æ
                plot_label_analysis(csv_file)
        except Exception as e:
            print(f"âŒ åˆ†ææ–‡ä»¶ {csv_file} æ—¶å‡ºé”™: {e}")
    
    # ç»¼åˆç»Ÿè®¡
    if all_results:
        print(f"\nğŸ“‹ ç»¼åˆåˆ†æç»“æœ (å…±{len(all_results)}ä¸ªæ–‡ä»¶):")
        
        # å¹³å‡ä¿¡å·å¯†åº¦
        avg_signal_density = np.mean([r['signal_density'] for r in all_results])
        print(f"   å¹³å‡ä¿¡å·å¯†åº¦: {avg_signal_density:.3f}")
        
        # æ ‡ç­¾åˆ†å¸ƒç»Ÿè®¡
        all_label_counts = Counter()
        for result in all_results:
            all_label_counts.update(result['label_distribution'])
        
        total_all_labels = sum(all_label_counts.values())
        print(f"   æ•´ä½“æ ‡ç­¾åˆ†å¸ƒ:")
        label_names = {0: 'æ— æ“ä½œ', 1: 'åšå¤šå¼€ä»“', 2: 'åšå¤šå¹³ä»“', 3: 'åšç©ºå¼€ä»“', 4: 'åšç©ºå¹³ä»“'}
        for label, count in sorted(all_label_counts.items()):
            percentage = count / total_all_labels * 100
            label_name = label_names.get(label, f'æœªçŸ¥æ ‡ç­¾{label}')
            print(f"     {label_name}: {count} ({percentage:.1f}%)")
    
    # ç»™å‡ºæ”¹è¿›å»ºè®®
    provide_improvement_suggestions(all_results)

def provide_improvement_suggestions(results):
    """
    åŸºäºåˆ†æç»“æœæä¾›æ”¹è¿›å»ºè®®
    """
    print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    
    if not results:
        print("   æ— æ³•æä¾›å»ºè®®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        return
    
    # åˆ†æä¿¡å·å¯†åº¦
    avg_signal_density = np.mean([r['signal_density'] for r in results])
    
    if avg_signal_density < 0.05:
        print("   ğŸ”¸ ä¿¡å·å¯†åº¦è¿‡ä½(<5%)ï¼Œå»ºè®®ï¼š")
        print("     - é™ä½æ ‡ç­¾ç”Ÿæˆçš„é˜ˆå€¼")
        print("     - ä½¿ç”¨æ›´æ•æ„Ÿçš„ä¿¡å·æ£€æµ‹æ–¹æ³•")
        print("     - è€ƒè™‘ä½¿ç”¨æ›´çŸ­çš„æ—¶é—´çª—å£")
    elif avg_signal_density > 0.3:
        print("   ğŸ”¸ ä¿¡å·å¯†åº¦è¿‡é«˜(>30%)ï¼Œå»ºè®®ï¼š")
        print("     - æé«˜æ ‡ç­¾ç”Ÿæˆçš„é˜ˆå€¼")
        print("     - å¢åŠ ä¿¡å·è¿‡æ»¤æ¡ä»¶")
        print("     - ä½¿ç”¨æ›´é•¿çš„æ—¶é—´çª—å£")
    else:
        print("   âœ… ä¿¡å·å¯†åº¦é€‚ä¸­ (5%-30%)")
    
    # åˆ†ææ ‡ç­¾å¹³è¡¡æ€§
    all_label_counts = Counter()
    for result in results:
        all_label_counts.update(result['label_distribution'])
    
    # æ’é™¤æ— æ“ä½œæ ‡ç­¾
    signal_labels = {k: v for k, v in all_label_counts.items() if k != 0}
    if signal_labels:
        max_count = max(signal_labels.values())
        min_count = min(signal_labels.values())
        imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')
        
        if imbalance_ratio > 5:
            print("   ğŸ”¸ æ ‡ç­¾ä¸¥é‡ä¸å¹³è¡¡ï¼Œå»ºè®®ï¼š")
            print("     - ä½¿ç”¨SMOTEç­‰è¿‡é‡‡æ ·æŠ€æœ¯")
            print("     - è°ƒæ•´æ ‡ç­¾ç”Ÿæˆç­–ç•¥ä½¿å„ç±»åˆ«æ›´å¹³è¡¡")
            print("     - ä½¿ç”¨åŠ æƒæŸå¤±å‡½æ•°")
        elif imbalance_ratio > 2:
            print("   ğŸ”¸ æ ‡ç­¾è½»å¾®ä¸å¹³è¡¡ï¼Œå»ºè®®ï¼š")
            print("     - ä½¿ç”¨ç±»åˆ«æƒé‡")
            print("     - è€ƒè™‘Focal Loss")
        else:
            print("   âœ… æ ‡ç­¾åˆ†å¸ƒç›¸å¯¹å¹³è¡¡")
    
    print("\nğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®ï¼š")
    print("   1. è¿è¡Œ predict_improved.py æŸ¥çœ‹å½“å‰æ¨¡å‹æ•ˆæœ")
    print("   2. æ ¹æ®åˆ†æç»“æœè°ƒæ•´æ ‡ç­¾ç”Ÿæˆå‚æ•°")
    print("   3. å¢åŠ æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾")
    print("   4. ä½¿ç”¨æ”¹è¿›çš„æ¨¡å‹æ¶æ„")
    print("   5. å®æ–½é›†æˆå­¦ä¹ æ–¹æ³•")

if __name__ == "__main__":
    # è¿è¡Œç»¼åˆåˆ†æ
    comprehensive_label_analysis()
    
    print(f"\n{'='*60}")
    print("æ ‡ç­¾è´¨é‡åˆ†æå®Œæˆï¼")
    print("è¯·æŸ¥çœ‹ç”Ÿæˆçš„åˆ†æå›¾è¡¨å’Œå»ºè®®ï¼Œç„¶åé’ˆå¯¹æ€§åœ°æ”¹è¿›æ¨¡å‹ã€‚")